{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejkiwi/mogumogu/blob/main/mgmg_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FMvuTnEWR1t"
      },
      "source": [
        "#cnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogxHsZSSWNjV"
      },
      "outputs": [],
      "source": [
        "import torch #pytorch 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI97cZ10Wbc2",
        "outputId": "1ff9eff8-9c48-4253-910d-9284fffb9404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:02<00:00, 4587668.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 134297.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1271405.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4603801.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#데이터셋불러오고 텐서로 바꿔주기\n",
        "from torchvision import datasets #데이터셋 불러오고\n",
        "from torchvision.transforms import ToTensor #텐서로 바꿔주기\n",
        "\n",
        "#datasets에서 MNIST 가져와서 훈련데이터와 테스트데이터 가져와주기.\n",
        "#datasets.MNIST(root - 데이터가 저장될 경로, train - train이 true 이면 train data이고 false면 test data, download - 데이터 없으면 인터넷에서 다운로드해줌 , transform - transform을 ToTensor로 지정해주지 않으면 텐서의 형식이 아닌, PIL이미지로 데이터가 가져와지게 된다, target_transform)\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root = \"data\",\n",
        "    train = True, #train data를 다운로드\n",
        "    transform = ToTensor(),\n",
        "    download = True\n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = False, #test data를 다운로드\n",
        "    transform = ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHv_Zs7eWdgY",
        "outputId": "12ab118b-eaa5-4ab6-929e-4f90ec0130ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "torch.Size([60000, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "#학습데이터 확인\n",
        "print(train_data)\n",
        "print(train_data.data.size())\n",
        "# 데이터셋의 이름은 MNIST\n",
        "# 데이터의 수는 60000개\n",
        "# 훈련데이터\n",
        "# StandardTransform(데이터셋에 일관되게 적용되는 변환의 표준을 정의) -> Transform: ToTensor() #이미지 데이터들을 모두 일관되게 텐서 형태로 변환하겠다는 것을 의미."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo_j68c0WgDi",
        "outputId": "41b3c1ff-d5d2-4518-87db-f275304e1893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "torch.Size([10000, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "#테스트데이터 확인\n",
        "print(test_data)\n",
        "print(test_data.data.size())\n",
        "#데이터의 수가 10000 인 것과 테스트데이터라는 것을 제외하면 나머지 속성은 학습데이터와 동일함."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "bYUaNlOeWik1",
        "outputId": "785cb459-e199-49ec-9217-682175ea4f45"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>matplotlib.pyplot.show</b><br/>def show(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py</a>Display all open figures.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "block : bool, optional\n",
              "    Whether to wait for all figures to be closed before returning.\n",
              "\n",
              "    If `True` block and run the GUI main loop until all figure windows\n",
              "    are closed.\n",
              "\n",
              "    If `False` ensure that all figure windows are displayed and return\n",
              "    immediately.  In this case, you are responsible for ensuring\n",
              "    that the event loop is running to have responsive figures.\n",
              "\n",
              "    Defaults to True in non-interactive mode and to False in interactive\n",
              "    mode (see `.pyplot.isinteractive`).\n",
              "\n",
              "See Also\n",
              "--------\n",
              "ion : Enable interactive mode, which shows / updates the figure after\n",
              "      every plotting command, so that calling ``show()`` is not necessary.\n",
              "ioff : Disable interactive mode.\n",
              "savefig : Save the figure to an image file instead of showing it on screen.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "**Saving figures to file and showing a window at the same time**\n",
              "\n",
              "If you want an image file as well as a user interface window, use\n",
              "`.pyplot.savefig` before `.pyplot.show`. At the end of (a blocking)\n",
              "``show()`` the figure is closed and thus unregistered from pyplot. Calling\n",
              "`.pyplot.savefig` afterwards would save a new and thus empty figure. This\n",
              "limitation of command order does not apply if the show is non-blocking or\n",
              "if you keep a reference to the figure and use `.Figure.savefig`.\n",
              "\n",
              "**Auto-show in jupyter notebooks**\n",
              "\n",
              "The jupyter backends (activated via ``%matplotlib inline``,\n",
              "``%matplotlib notebook``, or ``%matplotlib widget``), call ``show()`` at\n",
              "the end of every cell by default. Thus, you usually don&#x27;t have to call it\n",
              "explicitly there.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 401);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#데이터 시각적으로 확인\n",
        "import matplotlib.pyplot as plt #시각적 확인을 위해 matplotlib을 사용.\n",
        "fig, ax = plt.subplots() # fig -> 데이터가 담기는 프레임 / ax -> 실제 데이터가 그려지는 캔버스\n",
        "ax.imshow(train_data.data[0], cmap='gray') #데이터의 모습\n",
        "\n",
        "#이미지 위에 각 픽셀 값을 표시해서 나타내보기\n",
        "for i in range(train_data.data[0].shape[0]): # i와j는 텍스트를 표시할 위치를 지정하기 위함.\n",
        "  for j in range(train_data.data[0].shape[1]):\n",
        "    c = 1 if train_data.data[0][i, j].item() < 125 else 0 # 이미지의 각 픽셀 값( train_data.data[0][i,j].item() )이 125보다 작으면 c = 1 흰색을 사용, 크면 c = 0 검정 사용.\n",
        "    ax.text(j, i, str(train_data.data[0][i, j].item()), color=(c, c, c), ha='center', va='center', fontsize=5) # text()를 사용하여 이미지 위에 텍스트 그리기\n",
        "\n",
        "plt.title(\"%i\" % train_data.targets[0])\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYcY2R2mWkcO",
        "outputId": "e52a9553-954b-4fcf-84c0-3a621a13becb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x800 with 25 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#랜덤으로 데이터 뽑아서 확인\n",
        "figure = plt.figure(figsize=(10, 8))\n",
        "cols, rows = 5, 5\n",
        "for i in range(1, cols * rows + 1):\n",
        "  sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
        "  img, label= train_data[sample_idx]\n",
        "  figure.add_subplot(rows, cols, i)\n",
        "  plt.title(label)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk4WLXAwWmdZ",
        "outputId": "e247fbdc-8e02-4c14-e17e-0902693144e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7b96d593e680>,\n",
              " 'test': <torch.utils.data.dataloader.DataLoader at 0x7b96d593e5f0>}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "loaders = {\n",
        "    'train' : torch.utils.data.DataLoader(train_data,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=1),\n",
        "    'test' : torch.utils.data.DataLoader(test_data,\n",
        "                                         batch_size=100,\n",
        "                                         shuffle=True,\n",
        "                                         num_workers=1)\n",
        "}\n",
        "loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuSeXMWYWoWj"
      },
      "outputs": [],
      "source": [
        "class CNN(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.layer1 = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2), #컨볼루션 레이어(합성곱층) #1차원 데이터를 받아 16개의 feature로 나누겟다!!임.\n",
        "        torch.nn.ReLU(), #ReLU층\n",
        "        torch.nn.MaxPool2d(kernel_size=2, stride=2)) #풀링층\n",
        "    self.layer2 = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    self.fc = torch.nn.Linear(32 * 7 * 7, 10, bias=True) #32*7*7만큼의 입력을 linear레이어에 의해 계산되게 해서... 10개의 출력이 나오도록 함.\n",
        "    torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "    # __init__에서 정의내린 레이어들을\n",
        "    # 아래 forward(얘가 실제적인 모델의 형태가 됨)에서 사용한다.\n",
        "\n",
        "  def forward(self, x): #순전파\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMzwcnPwWqfd",
        "outputId": "8c0ab35a-a368-4d3b-cd1f-4e676ccb39b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=1568, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = CNN()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7X0kP2gWuVm"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer =  torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "training_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch = len(loaders['train'])\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for X, Y in loaders['train']:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(X)  # 순전파\n",
        "        cost = loss_func(pred, Y)  # 손실 함수 계산\n",
        "        cost.backward()  # 역전파\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "        # 정확도 계산\n",
        "        _, predicted = torch.max(pred, 1)  # 예측한 클래스\n",
        "        total += Y.size(0)  # 총 라벨 수\n",
        "        correct += (predicted == Y).sum().item()  # 맞춘 예측 수\n",
        "\n",
        "    accuracy = 100 * correct / total  # 정확도 계산\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}, accuracy = {:.2f}%'.format(epoch + 1, avg_cost, accuracy))\n",
        "\n",
        "print('Learning Finished....>_<')"
      ],
      "metadata": {
        "id": "kPcCWHi6LruY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJVSFqL4Wxgt",
        "outputId": "552689ef-3e5c-4d53-af38-9c1c07b4cb09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch:    1] cost = 0.134813368\n",
            "[Epoch:    2] cost = 0.0565370545\n",
            "[Epoch:    3] cost = 0.0467693619\n",
            "[Epoch:    4] cost = 0.0408988632\n",
            "[Epoch:    5] cost = 0.0388146788\n",
            "[Epoch:    6] cost = 0.0372155495\n",
            "[Epoch:    7] cost = 0.0407399572\n",
            "[Epoch:    8] cost = 0.0360557809\n",
            "[Epoch:    9] cost = 0.0307568833\n",
            "[Epoch:   10] cost = 0.0338073261\n",
            "Learning Finished....>_<\n"
          ]
        }
      ],
      "source": [
        "# total_batch = len(loaders['train'])\n",
        "# for epoch in range(training_epochs):\n",
        "#   avg_cost = 0\n",
        "\n",
        "#   for X, Y in loaders['train']:\n",
        "#     optimizer.zero_grad()\n",
        "#     pred = model(X) #순전파\n",
        "#     cost = loss_func(pred, Y) #손실함수계산\n",
        "#     cost.backward() #역전파\n",
        "#     optimizer.step()\n",
        "\n",
        "#     avg_cost += cost / total_batch\n",
        "\n",
        "#   print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
        "#   # print('[Epoch: ', epoch + 1, ']  ','cost = ', avg_cost)\n",
        "# print('Learning Finished....>_<')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpwnOddtWXDN"
      },
      "source": [
        "#resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq2FmQKNW0ny"
      },
      "outputs": [],
      "source": [
        "#필요한 모듈 불러오기\n",
        "import torch\n",
        "import torch.nn as nn #다양한 종류의 레이어 제공 -> 모델 만들기 도우미!\n",
        "import torch.nn.functional as F #활성화 함수, 손실함수 등을 함수 형태로 제공.\n",
        "import torch.optim as optim\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1JIO9zGW38K"
      },
      "outputs": [],
      "source": [
        "#BasicBlock 클래스 정의\n",
        "\n",
        "class BasicBlock(nn.Module): # nn.Module 상속받기\n",
        "    def __init__(self, in_planes, planes, stride = 1):\n",
        "        super(BasicBlock, self).__init__() #BasicBlock의 부모클래스인 nn.Module의 __init__함수를 먼저 호출해서 사용.\n",
        "\n",
        "        #conv1과 conv2 설정\n",
        "        #2D 컨볼루션 레이어 설정\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size = 3, stride = stride, padding = 1, bias = False) # in_planes 입력채널 수 / planes 출력채널 수 / kernel_size 3*3 필터(커널) 사용 / stride (커널로 훑을 때의 보폭) 기본값은 1 / padding 패딩의 크기 1 / bias = False 바이어스(출력값을 조절하기 위해 사용되는  값) 를 사용하지 않겠다. -> 바로 다음 줄의 코드(배치정규화)에서 바이어스의 역할을 해주기 때문에 여기에선 사용하지 않는다.\n",
        "        #배치 정규화 설정\n",
        "        self.bn1 = nn.BatchNorm2d(planes) # planes 배치정규화를 적용할 채널의 수. 앞의 출력 채널의 수와 동일해야함(당연함)\n",
        "\n",
        "        #2D 컨볼루션 레이어 설정\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        #배치 정규화 설정\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "# shortcut 설정 -> `H(x) = R(x) + x`에서의 x를 위한 작업\n",
        "        self.shortcut = nn.Sequential() # nn.Sequential : pytorch에서 여러 레이어들을 순서대로 쌓을 때 사용하는 도구 # x를 그대로 더할 수 있는 경우\n",
        "        if stride != 1: #stride의 값이 1인경우(입력과 출력의 채널 수가 다른 경우 = x를 그대로 더할 수 없는 경우)\n",
        "          self.shortcut = nn.Sequential(\n",
        "                          nn.Conv2d(in_planes, planes, kernel_size = 1, stride = stride, bias = False),\n",
        "                          nn.BatchNorm2d(planes)\n",
        "                      ) # nn.Sequential을 사용해서 Conv2d와 BatchNorm레이어들을 이어줬음\n",
        "\n",
        "#순전파 함수 # __init__에서 설정해뒀던 거 실제로 사용하는 부분.\n",
        "    def forward(self,x):\n",
        "        out = F.relu(self.bn1(self.conv1(x))) #conv1 거치고, relu함수 거치기\n",
        "        out = self.bn2(self.conv2(out)) #그다음 conv2 거치기\n",
        "        out += self.shortcut(x) # resnet의 핵심인 skip connection : H(x) = R(x) + x\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZOYGsM-W6K3"
      },
      "outputs": [],
      "source": [
        "#ResNet 클래스 정의\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes = 10):\n",
        "        super(ResNet, self).__init__() #ResNet의 부모클래스인 nn.Module의 __init__함수를 먼저 호출해서 사용.\n",
        "        self.in_planes = 64 # 입력 채널 수 64        # 2D 컨볼루션레이어 설정\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size = 3, stride = 1, padding = 1, bias = False) # 입력채널 수 3 / 출력채널 수 64 / kernel_size 3*3 필터(커널) 사용 / stride (커널로 훑을 때의 보폭) 1 / padding 패딩의 크기 1 / bias = False 바이어스(출력값을 조절하기 위해 사용되는  값) 를 사용하지 않겠다.\n",
        "        # 배치정규화 설정\n",
        "        self.bn1 = nn.BatchNorm2d(64) # 배치정규화를 위해 사용할 채널 수 = 이전 채널에서의 출력 채널 수 = 64        # 레이어블록 설정(각 블록은 앞서 정의한 BASIC BLOCK으로 구성될거임. 인자 block 자리에, BasicBlock이 들어갈거니까아아아~~)\n",
        "        # _make_layer() : (블록의 종류, 출력 채널 수, 쌓을 블럭의 수, 레이어의 첫 블럭에서 사용할 stride의 값)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride = 1) #\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride = 2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride = 2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        # self._make_layer()에서 self는 현재 클래스의 인스턴스를 가리킴.\n",
        "        # 클래스 예측값 계산\n",
        "        self.linear = nn.Linear(512, num_classes) # 입력 채널 수 512, 출력 채널 수 num_classes        # _make_layer 함수 설정\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks -1) # stride 값 설정 # 첫 번째 블록의 stride는 지정된 값을 사용하고 이후 블럭들은 stride = 1이 된다.\n",
        "        layers = [] # 블럭을 담을 빈 리스트 생성\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride)) # 입력 채널 수 self.in_planes, 출력 채널 수 planes, 스트라이드 값 stride\n",
        "            self.in_planes = planes # 채널 수 변경해주기(다음 레이어를 위해)\n",
        "        return nn.Sequential(*layers) # 생성한 블록들을 하나의 레이어로 묶어서 반환.\n",
        "    # 순전파 함수 # __init__ 설정해뒀던거랑 _make_layer 함수 만든 거 실제로 사용하는 부분.\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4) # 풀링층\n",
        "        out = out.view(out.size(0),-1) # 텐서의 차원 변경\n",
        "        out = self.linear(out) #완전 연결층\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FERJsCr6W-MV"
      },
      "outputs": [],
      "source": [
        "# ResNet 18 함수 정의\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wtbus0UWXAPp",
        "outputId": "cf7e1a7f-0d74-447e-ade8-53d9b036e704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# 데이터 불러오기\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JueFErsGcDWN"
      },
      "outputs": [],
      "source": [
        "# 학습 준비\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "net = ResNet18()\n",
        "net = net.to(device)\n",
        "\n",
        "\n",
        "learning_rate = 0.1\n",
        "file_name = 'resnet18_cifar10.pth'\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    print('\\n[ Train epoch: %d ]' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "\n",
        "        total += targets.size(0)\n",
        "        current_correct = predicted.eq(targets).sum().item()\n",
        "        correct += current_correct\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('\\nCurrent batch:', str(batch_idx))\n",
        "            print('Current batch average train accuracy:', current_correct / targets.size(0))\n",
        "            print('Current batch average train loss:', loss.item() / targets.size(0))\n",
        "\n",
        "    print('\\nTotal average train accuarcy:', correct / total)\n",
        "    print('Total average train loss:', train_loss / total)\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    print('\\n[ Test epoch: %d ]' % epoch)\n",
        "    net.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        total += targets.size(0)\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss += criterion(outputs, targets).item()\n",
        "\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print('\\nTotal average test accuarcy:', correct / total)\n",
        "    print('Total average test loss:', loss / total)\n",
        "\n",
        "    state = {\n",
        "        'net': net.state_dict()\n",
        "    }\n",
        "    if not os.path.isdir('checkpoint'):\n",
        "        os.mkdir('checkpoint')\n",
        "    torch.save(state, './checkpoint/' + file_name)\n",
        "    print('Model Saved!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7ej6OyjcVF3",
        "outputId": "e3111989-2de5-498e-f394-d6cdbf05c020"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[ Train epoch: 0 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.09375\n",
            "Current batch average train loss: 0.018409598618745804\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.2421875\n",
            "Current batch average train loss: 0.01531041320413351\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.3203125\n",
            "Current batch average train loss: 0.013150942511856556\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.3671875\n",
            "Current batch average train loss: 0.013146699406206608\n",
            "\n",
            "Total average train accuarcy: 0.30494\n",
            "Total average train loss: 0.01627366531133652\n",
            "\n",
            "[ Test epoch: 0 ]\n",
            "\n",
            "Total average test accuarcy: 0.4128\n",
            "Total average test loss: 0.016303587591648103\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 48.389663219451904\n",
            "\n",
            "[ Train epoch: 1 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.4296875\n",
            "Current batch average train loss: 0.012642751447856426\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.3125\n",
            "Current batch average train loss: 0.01450985949486494\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.3359375\n",
            "Current batch average train loss: 0.012843301519751549\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.4375\n",
            "Current batch average train loss: 0.011652541346848011\n",
            "\n",
            "Total average train accuarcy: 0.41368\n",
            "Total average train loss: 0.01230942170381546\n",
            "\n",
            "[ Test epoch: 1 ]\n",
            "\n",
            "Total average test accuarcy: 0.4576\n",
            "Total average test loss: 0.015157651734352112\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 95.82593631744385\n",
            "\n",
            "[ Train epoch: 2 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.546875\n",
            "Current batch average train loss: 0.010724940337240696\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.46875\n",
            "Current batch average train loss: 0.012036065571010113\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.5234375\n",
            "Current batch average train loss: 0.010844276286661625\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.5390625\n",
            "Current batch average train loss: 0.009726609103381634\n",
            "\n",
            "Total average train accuarcy: 0.47424\n",
            "Total average train loss: 0.011239002497196197\n",
            "\n",
            "[ Test epoch: 2 ]\n",
            "\n",
            "Total average test accuarcy: 0.4677\n",
            "Total average test loss: 0.015345269346237183\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 143.49109387397766\n",
            "\n",
            "[ Train epoch: 3 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.4765625\n",
            "Current batch average train loss: 0.010699690319597721\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.5625\n",
            "Current batch average train loss: 0.009703189134597778\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.421875\n",
            "Current batch average train loss: 0.011754856444895267\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.5\n",
            "Current batch average train loss: 0.010350339114665985\n",
            "\n",
            "Total average train accuarcy: 0.52974\n",
            "Total average train loss: 0.01014677549481392\n",
            "\n",
            "[ Test epoch: 3 ]\n",
            "\n",
            "Total average test accuarcy: 0.3233\n",
            "Total average test loss: 0.024941694378852845\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 191.10251927375793\n",
            "\n",
            "[ Train epoch: 4 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.578125\n",
            "Current batch average train loss: 0.008744338527321815\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.65625\n",
            "Current batch average train loss: 0.007233099080622196\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.6171875\n",
            "Current batch average train loss: 0.008966002613306046\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.5625\n",
            "Current batch average train loss: 0.009490067139267921\n",
            "\n",
            "Total average train accuarcy: 0.5832\n",
            "Total average train loss: 0.009053421038389206\n",
            "\n",
            "[ Test epoch: 4 ]\n",
            "\n",
            "Total average test accuarcy: 0.5018\n",
            "Total average test loss: 0.014489696288108825\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 238.83059906959534\n",
            "\n",
            "[ Train epoch: 5 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.5546875\n",
            "Current batch average train loss: 0.009115331806242466\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.5625\n",
            "Current batch average train loss: 0.0084567004814744\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.609375\n",
            "Current batch average train loss: 0.00936780497431755\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.65625\n",
            "Current batch average train loss: 0.008312179706990719\n",
            "\n",
            "Total average train accuarcy: 0.62248\n",
            "Total average train loss: 0.008321863837242127\n",
            "\n",
            "[ Test epoch: 5 ]\n",
            "\n",
            "Total average test accuarcy: 0.4879\n",
            "Total average test loss: 0.017285990703105925\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 286.389279127121\n",
            "\n",
            "[ Train epoch: 6 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.671875\n",
            "Current batch average train loss: 0.007279613986611366\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.6484375\n",
            "Current batch average train loss: 0.007540250197052956\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.7265625\n",
            "Current batch average train loss: 0.006460985168814659\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.625\n",
            "Current batch average train loss: 0.007707450073212385\n",
            "\n",
            "Total average train accuarcy: 0.655\n",
            "Total average train loss: 0.007604264258146286\n",
            "\n",
            "[ Test epoch: 6 ]\n",
            "\n",
            "Total average test accuarcy: 0.4715\n",
            "Total average test loss: 0.016340165543556214\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 334.19221472740173\n",
            "\n",
            "[ Train epoch: 7 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.6484375\n",
            "Current batch average train loss: 0.007127530872821808\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.671875\n",
            "Current batch average train loss: 0.007210038602352142\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.6875\n",
            "Current batch average train loss: 0.007364208810031414\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.703125\n",
            "Current batch average train loss: 0.006020514760166407\n",
            "\n",
            "Total average train accuarcy: 0.6801\n",
            "Total average train loss: 0.007096723781824112\n",
            "\n",
            "[ Test epoch: 7 ]\n",
            "\n",
            "Total average test accuarcy: 0.6692\n",
            "Total average test loss: 0.00954398118853569\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 381.47485756874084\n",
            "\n",
            "[ Train epoch: 8 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.6875\n",
            "Current batch average train loss: 0.007571536116302013\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.703125\n",
            "Current batch average train loss: 0.007146524731069803\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.734375\n",
            "Current batch average train loss: 0.00634003197774291\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.7265625\n",
            "Current batch average train loss: 0.006211747881025076\n",
            "\n",
            "Total average train accuarcy: 0.69766\n",
            "Total average train loss: 0.00671014023900032\n",
            "\n",
            "[ Test epoch: 8 ]\n",
            "\n",
            "Total average test accuarcy: 0.5565\n",
            "Total average test loss: 0.013814552116394043\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 428.96334052085876\n",
            "\n",
            "[ Train epoch: 9 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.703125\n",
            "Current batch average train loss: 0.0067016687244176865\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.7421875\n",
            "Current batch average train loss: 0.006208057515323162\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.640625\n",
            "Current batch average train loss: 0.007325840648263693\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.8125\n",
            "Current batch average train loss: 0.004408762324601412\n",
            "\n",
            "Total average train accuarcy: 0.72144\n",
            "Total average train loss: 0.006206535676717758\n",
            "\n",
            "[ Test epoch: 9 ]\n",
            "\n",
            "Total average test accuarcy: 0.6775\n",
            "Total average test loss: 0.009232981061935425\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 476.8110291957855\n",
            "\n",
            "[ Train epoch: 10 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.7109375\n",
            "Current batch average train loss: 0.00631363969296217\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.6640625\n",
            "Current batch average train loss: 0.0075974841602146626\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.6875\n",
            "Current batch average train loss: 0.006086429581046104\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.78125\n",
            "Current batch average train loss: 0.005576213821768761\n",
            "\n",
            "Total average train accuarcy: 0.73912\n",
            "Total average train loss: 0.0058282143127918245\n",
            "\n",
            "[ Test epoch: 10 ]\n",
            "\n",
            "Total average test accuarcy: 0.7039\n",
            "Total average test loss: 0.008570668357610703\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 524.2193124294281\n",
            "\n",
            "[ Train epoch: 11 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.7734375\n",
            "Current batch average train loss: 0.0058388435281813145\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.78125\n",
            "Current batch average train loss: 0.004742408636957407\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.6796875\n",
            "Current batch average train loss: 0.006122496444731951\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.8203125\n",
            "Current batch average train loss: 0.005252458620816469\n",
            "\n",
            "Total average train accuarcy: 0.75904\n",
            "Total average train loss: 0.005399556249380112\n",
            "\n",
            "[ Test epoch: 11 ]\n",
            "\n",
            "Total average test accuarcy: 0.6217\n",
            "Total average test loss: 0.012493236023187637\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 571.6375501155853\n",
            "\n",
            "[ Train epoch: 12 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.7578125\n",
            "Current batch average train loss: 0.004922148771584034\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.84375\n",
            "Current batch average train loss: 0.003570229047909379\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.7734375\n",
            "Current batch average train loss: 0.004933309741318226\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.84375\n",
            "Current batch average train loss: 0.004346092697232962\n",
            "\n",
            "Total average train accuarcy: 0.77704\n",
            "Total average train loss: 0.005012826057076454\n",
            "\n",
            "[ Test epoch: 12 ]\n",
            "\n",
            "Total average test accuarcy: 0.7315\n",
            "Total average test loss: 0.007948762780427932\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 619.472650051117\n",
            "\n",
            "[ Train epoch: 13 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.7734375\n",
            "Current batch average train loss: 0.00539266737177968\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.78125\n",
            "Current batch average train loss: 0.004826792515814304\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.828125\n",
            "Current batch average train loss: 0.004718753509223461\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.7578125\n",
            "Current batch average train loss: 0.005519623402506113\n",
            "\n",
            "Total average train accuarcy: 0.7914\n",
            "Total average train loss: 0.004719599657654762\n",
            "\n",
            "[ Test epoch: 13 ]\n",
            "\n",
            "Total average test accuarcy: 0.7041\n",
            "Total average test loss: 0.009319431227445602\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 666.8683240413666\n",
            "\n",
            "[ Train epoch: 14 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8671875\n",
            "Current batch average train loss: 0.0032286248169839382\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8203125\n",
            "Current batch average train loss: 0.004969461355358362\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.75\n",
            "Current batch average train loss: 0.0051763057708740234\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.875\n",
            "Current batch average train loss: 0.003394840285181999\n",
            "\n",
            "Total average train accuarcy: 0.80156\n",
            "Total average train loss: 0.004481036068201065\n",
            "\n",
            "[ Test epoch: 14 ]\n",
            "\n",
            "Total average test accuarcy: 0.7705\n",
            "Total average test loss: 0.006984870693087578\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 714.3267703056335\n",
            "\n",
            "[ Train epoch: 15 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8359375\n",
            "Current batch average train loss: 0.00339857442304492\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8125\n",
            "Current batch average train loss: 0.004348236136138439\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.8203125\n",
            "Current batch average train loss: 0.0045210225507617\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.828125\n",
            "Current batch average train loss: 0.004203087650239468\n",
            "\n",
            "Total average train accuarcy: 0.80914\n",
            "Total average train loss: 0.004319792329668999\n",
            "\n",
            "[ Test epoch: 15 ]\n",
            "\n",
            "Total average test accuarcy: 0.7709\n",
            "Total average test loss: 0.006766720461845398\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 762.228057384491\n",
            "\n",
            "[ Train epoch: 16 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.7734375\n",
            "Current batch average train loss: 0.00453150412067771\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8203125\n",
            "Current batch average train loss: 0.004350956995040178\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.84375\n",
            "Current batch average train loss: 0.004120018798857927\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.8671875\n",
            "Current batch average train loss: 0.0034327504690736532\n",
            "\n",
            "Total average train accuarcy: 0.81834\n",
            "Total average train loss: 0.004117671081423759\n",
            "\n",
            "[ Test epoch: 16 ]\n",
            "\n",
            "Total average test accuarcy: 0.7384\n",
            "Total average test loss: 0.008068661838769912\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 809.5672018527985\n",
            "\n",
            "[ Train epoch: 17 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8515625\n",
            "Current batch average train loss: 0.004039589781314135\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.84375\n",
            "Current batch average train loss: 0.004344365559518337\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.828125\n",
            "Current batch average train loss: 0.003061482682824135\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.8125\n",
            "Current batch average train loss: 0.004417665768414736\n",
            "\n",
            "Total average train accuarcy: 0.82574\n",
            "Total average train loss: 0.0039443377858400346\n",
            "\n",
            "[ Test epoch: 17 ]\n",
            "\n",
            "Total average test accuarcy: 0.7893\n",
            "Total average test loss: 0.006135980701446533\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 856.9381279945374\n",
            "\n",
            "[ Train epoch: 18 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8203125\n",
            "Current batch average train loss: 0.0039017931558191776\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8046875\n",
            "Current batch average train loss: 0.0037987129762768745\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.890625\n",
            "Current batch average train loss: 0.0034411947708576918\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.8359375\n",
            "Current batch average train loss: 0.003321088617667556\n",
            "\n",
            "Total average train accuarcy: 0.83314\n",
            "Total average train loss: 0.0037542918837070467\n",
            "\n",
            "[ Test epoch: 18 ]\n",
            "\n",
            "Total average test accuarcy: 0.7872\n",
            "Total average test loss: 0.00649992107450962\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 904.7868988513947\n",
            "\n",
            "[ Train epoch: 19 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8828125\n",
            "Current batch average train loss: 0.0025342758744955063\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8671875\n",
            "Current batch average train loss: 0.004152690060436726\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.8359375\n",
            "Current batch average train loss: 0.0034210223238915205\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.875\n",
            "Current batch average train loss: 0.0026241294108331203\n",
            "\n",
            "Total average train accuarcy: 0.83544\n",
            "Total average train loss: 0.0036828335255384447\n",
            "\n",
            "[ Test epoch: 19 ]\n",
            "\n",
            "Total average test accuarcy: 0.8136\n",
            "Total average test loss: 0.00557827216386795\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 952.2211520671844\n",
            "\n",
            "[ Train epoch: 20 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8203125\n",
            "Current batch average train loss: 0.004287462681531906\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8125\n",
            "Current batch average train loss: 0.004667534492909908\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.84375\n",
            "Current batch average train loss: 0.003511058632284403\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.796875\n",
            "Current batch average train loss: 0.003978438675403595\n",
            "\n",
            "Total average train accuarcy: 0.84136\n",
            "Total average train loss: 0.003567877759039402\n",
            "\n",
            "[ Test epoch: 20 ]\n",
            "\n",
            "Total average test accuarcy: 0.8001\n",
            "Total average test loss: 0.006276137688755989\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 999.7301781177521\n",
            "\n",
            "[ Train epoch: 21 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8828125\n",
            "Current batch average train loss: 0.0030261422507464886\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8203125\n",
            "Current batch average train loss: 0.0038206172175705433\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.8984375\n",
            "Current batch average train loss: 0.0023843487724661827\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.796875\n",
            "Current batch average train loss: 0.0036250771954655647\n",
            "\n",
            "Total average train accuarcy: 0.85062\n",
            "Total average train loss: 0.0034192540431022644\n",
            "\n",
            "[ Test epoch: 21 ]\n",
            "\n",
            "Total average test accuarcy: 0.8083\n",
            "Total average test loss: 0.00575121742784977\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1047.6664173603058\n",
            "\n",
            "[ Train epoch: 22 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8828125\n",
            "Current batch average train loss: 0.002972392365336418\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.796875\n",
            "Current batch average train loss: 0.004633520729839802\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.8828125\n",
            "Current batch average train loss: 0.0029316027648746967\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.875\n",
            "Current batch average train loss: 0.002627187641337514\n",
            "\n",
            "Total average train accuarcy: 0.84814\n",
            "Total average train loss: 0.0034080643585324287\n",
            "\n",
            "[ Test epoch: 22 ]\n",
            "\n",
            "Total average test accuarcy: 0.801\n",
            "Total average test loss: 0.006195480483770371\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1095.0385057926178\n",
            "\n",
            "[ Train epoch: 23 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8359375\n",
            "Current batch average train loss: 0.0033193854615092278\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8125\n",
            "Current batch average train loss: 0.0038333507254719734\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.828125\n",
            "Current batch average train loss: 0.0036748796701431274\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.875\n",
            "Current batch average train loss: 0.0028392754029482603\n",
            "\n",
            "Total average train accuarcy: 0.85776\n",
            "Total average train loss: 0.0032240142387151716\n",
            "\n",
            "[ Test epoch: 23 ]\n",
            "\n",
            "Total average test accuarcy: 0.8019\n",
            "Total average test loss: 0.006165107014775276\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1142.460412979126\n",
            "\n",
            "[ Train epoch: 24 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8671875\n",
            "Current batch average train loss: 0.0031757026445120573\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8515625\n",
            "Current batch average train loss: 0.003152549033984542\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.8828125\n",
            "Current batch average train loss: 0.0031620217487215996\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.8515625\n",
            "Current batch average train loss: 0.0034446031786501408\n",
            "\n",
            "Total average train accuarcy: 0.86056\n",
            "Total average train loss: 0.0031792113518714906\n",
            "\n",
            "[ Test epoch: 24 ]\n",
            "\n",
            "Total average test accuarcy: 0.8127\n",
            "Total average test loss: 0.0057085789173841476\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1190.3028342723846\n",
            "\n",
            "[ Train epoch: 25 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8359375\n",
            "Current batch average train loss: 0.0033448096364736557\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9140625\n",
            "Current batch average train loss: 0.002166071441024542\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9140625\n",
            "Current batch average train loss: 0.0027450169436633587\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.8515625\n",
            "Current batch average train loss: 0.002984649268910289\n",
            "\n",
            "Total average train accuarcy: 0.8625\n",
            "Total average train loss: 0.0031129411879181864\n",
            "\n",
            "[ Test epoch: 25 ]\n",
            "\n",
            "Total average test accuarcy: 0.7702\n",
            "Total average test loss: 0.006932004302740097\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1237.7930250167847\n",
            "\n",
            "[ Train epoch: 26 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.890625\n",
            "Current batch average train loss: 0.002426562365144491\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8125\n",
            "Current batch average train loss: 0.004346006084233522\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.828125\n",
            "Current batch average train loss: 0.0035195655655115843\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.875\n",
            "Current batch average train loss: 0.003656962653622031\n",
            "\n",
            "Total average train accuarcy: 0.86454\n",
            "Total average train loss: 0.003062092165350914\n",
            "\n",
            "[ Test epoch: 26 ]\n",
            "\n",
            "Total average test accuarcy: 0.8372\n",
            "Total average test loss: 0.00485955900400877\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1285.3087484836578\n",
            "\n",
            "[ Train epoch: 27 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.84375\n",
            "Current batch average train loss: 0.0030133211985230446\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9296875\n",
            "Current batch average train loss: 0.0022532588336616755\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.8359375\n",
            "Current batch average train loss: 0.003441654145717621\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.8828125\n",
            "Current batch average train loss: 0.0026423055678606033\n",
            "\n",
            "Total average train accuarcy: 0.86846\n",
            "Total average train loss: 0.0029933684265613554\n",
            "\n",
            "[ Test epoch: 27 ]\n",
            "\n",
            "Total average test accuarcy: 0.833\n",
            "Total average test loss: 0.005092478188872337\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1332.9480578899384\n",
            "\n",
            "[ Train epoch: 28 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8828125\n",
            "Current batch average train loss: 0.0028825784102082253\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.890625\n",
            "Current batch average train loss: 0.002538829343393445\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.8828125\n",
            "Current batch average train loss: 0.002834020182490349\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.8671875\n",
            "Current batch average train loss: 0.0037941744085401297\n",
            "\n",
            "Total average train accuarcy: 0.87094\n",
            "Total average train loss: 0.0029331619936227796\n",
            "\n",
            "[ Test epoch: 28 ]\n",
            "\n",
            "Total average test accuarcy: 0.8209\n",
            "Total average test loss: 0.005547903311252594\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1380.5896210670471\n",
            "\n",
            "[ Train epoch: 29 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.90625\n",
            "Current batch average train loss: 0.0023196793626993895\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8515625\n",
            "Current batch average train loss: 0.003095232881605625\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9375\n",
            "Current batch average train loss: 0.0021534578409045935\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.84375\n",
            "Current batch average train loss: 0.002787490375339985\n",
            "\n",
            "Total average train accuarcy: 0.8733\n",
            "Total average train loss: 0.002885765196084976\n",
            "\n",
            "[ Test epoch: 29 ]\n",
            "\n",
            "Total average test accuarcy: 0.8125\n",
            "Total average test loss: 0.005615139704942703\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1428.3509075641632\n",
            "\n",
            "[ Train epoch: 30 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.890625\n",
            "Current batch average train loss: 0.002451022155582905\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.890625\n",
            "Current batch average train loss: 0.003203299129381776\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.8828125\n",
            "Current batch average train loss: 0.002103719860315323\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.875\n",
            "Current batch average train loss: 0.0031547262333333492\n",
            "\n",
            "Total average train accuarcy: 0.87692\n",
            "Total average train loss: 0.002828730516433716\n",
            "\n",
            "[ Test epoch: 30 ]\n",
            "\n",
            "Total average test accuarcy: 0.7907\n",
            "Total average test loss: 0.006192197415232658\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1475.8427970409393\n",
            "\n",
            "[ Train epoch: 31 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.875\n",
            "Current batch average train loss: 0.0022163877729326487\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.890625\n",
            "Current batch average train loss: 0.003134477185085416\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.890625\n",
            "Current batch average train loss: 0.0025072768330574036\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.90625\n",
            "Current batch average train loss: 0.0024158209562301636\n",
            "\n",
            "Total average train accuarcy: 0.8784\n",
            "Total average train loss: 0.0027597489920258523\n",
            "\n",
            "[ Test epoch: 31 ]\n",
            "\n",
            "Total average test accuarcy: 0.8383\n",
            "Total average test loss: 0.0050406466901302335\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1523.2424170970917\n",
            "\n",
            "[ Train epoch: 32 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8984375\n",
            "Current batch average train loss: 0.0026754506397992373\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8984375\n",
            "Current batch average train loss: 0.002059265971183777\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.875\n",
            "Current batch average train loss: 0.0029948349110782146\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.90625\n",
            "Current batch average train loss: 0.0026663097087293863\n",
            "\n",
            "Total average train accuarcy: 0.87814\n",
            "Total average train loss: 0.002755340668559074\n",
            "\n",
            "[ Test epoch: 32 ]\n",
            "\n",
            "Total average test accuarcy: 0.8241\n",
            "Total average test loss: 0.005486349350214004\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1570.8869302272797\n",
            "\n",
            "[ Train epoch: 33 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.890625\n",
            "Current batch average train loss: 0.0025090458802878857\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.890625\n",
            "Current batch average train loss: 0.0019231243059039116\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.84375\n",
            "Current batch average train loss: 0.00294760731048882\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.84375\n",
            "Current batch average train loss: 0.003817001823335886\n",
            "\n",
            "Total average train accuarcy: 0.8785\n",
            "Total average train loss: 0.0027361805829405786\n",
            "\n",
            "[ Test epoch: 33 ]\n",
            "\n",
            "Total average test accuarcy: 0.8459\n",
            "Total average test loss: 0.004754404205083847\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1618.0845084190369\n",
            "\n",
            "[ Train epoch: 34 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.921875\n",
            "Current batch average train loss: 0.0016903833020478487\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.890625\n",
            "Current batch average train loss: 0.0022660165559500456\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.8984375\n",
            "Current batch average train loss: 0.003213129471987486\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9296875\n",
            "Current batch average train loss: 0.0017113253707066178\n",
            "\n",
            "Total average train accuarcy: 0.88214\n",
            "Total average train loss: 0.002657107240855694\n",
            "\n",
            "[ Test epoch: 34 ]\n",
            "\n",
            "Total average test accuarcy: 0.7739\n",
            "Total average test loss: 0.008025122511386871\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1665.3925540447235\n",
            "\n",
            "[ Train epoch: 35 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.859375\n",
            "Current batch average train loss: 0.003109848592430353\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8203125\n",
            "Current batch average train loss: 0.004098118282854557\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.90625\n",
            "Current batch average train loss: 0.0020237616263329983\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.8515625\n",
            "Current batch average train loss: 0.0033576986752450466\n",
            "\n",
            "Total average train accuarcy: 0.8827\n",
            "Total average train loss: 0.002643917030096054\n",
            "\n",
            "[ Test epoch: 35 ]\n",
            "\n",
            "Total average test accuarcy: 0.8173\n",
            "Total average test loss: 0.005720440281927586\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1713.1882905960083\n",
            "\n",
            "[ Train epoch: 36 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.859375\n",
            "Current batch average train loss: 0.002991856075823307\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.875\n",
            "Current batch average train loss: 0.002896109828725457\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.921875\n",
            "Current batch average train loss: 0.001937359687872231\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.8984375\n",
            "Current batch average train loss: 0.0021549903322011232\n",
            "\n",
            "Total average train accuarcy: 0.88632\n",
            "Total average train loss: 0.0026010079064965248\n",
            "\n",
            "[ Test epoch: 36 ]\n",
            "\n",
            "Total average test accuarcy: 0.8302\n",
            "Total average test loss: 0.005079511691629886\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1760.401201248169\n",
            "\n",
            "[ Train epoch: 37 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9296875\n",
            "Current batch average train loss: 0.0016129891155287623\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8203125\n",
            "Current batch average train loss: 0.0038106224965304136\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.8828125\n",
            "Current batch average train loss: 0.0028419210575520992\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.84375\n",
            "Current batch average train loss: 0.003230104222893715\n",
            "\n",
            "Total average train accuarcy: 0.88836\n",
            "Total average train loss: 0.002530044758617878\n",
            "\n",
            "[ Test epoch: 37 ]\n",
            "\n",
            "Total average test accuarcy: 0.8465\n",
            "Total average test loss: 0.004660063508152961\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1807.7775745391846\n",
            "\n",
            "[ Train epoch: 38 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9453125\n",
            "Current batch average train loss: 0.001581687363795936\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8984375\n",
            "Current batch average train loss: 0.0019248019671067595\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.875\n",
            "Current batch average train loss: 0.0029692198149859905\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9140625\n",
            "Current batch average train loss: 0.0022594756446778774\n",
            "\n",
            "Total average train accuarcy: 0.88906\n",
            "Total average train loss: 0.0025323091277480126\n",
            "\n",
            "[ Test epoch: 38 ]\n",
            "\n",
            "Total average test accuarcy: 0.824\n",
            "Total average test loss: 0.005643174731731415\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1855.6088328361511\n",
            "\n",
            "[ Train epoch: 39 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9296875\n",
            "Current batch average train loss: 0.0016235574148595333\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.921875\n",
            "Current batch average train loss: 0.0018191091949120164\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.84375\n",
            "Current batch average train loss: 0.0029663839377462864\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9140625\n",
            "Current batch average train loss: 0.0019235450308769941\n",
            "\n",
            "Total average train accuarcy: 0.88954\n",
            "Total average train loss: 0.0024848582702875137\n",
            "\n",
            "[ Test epoch: 39 ]\n",
            "\n",
            "Total average test accuarcy: 0.851\n",
            "Total average test loss: 0.0046016076937317844\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1902.7740576267242\n",
            "\n",
            "[ Train epoch: 40 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.828125\n",
            "Current batch average train loss: 0.003729200456291437\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9140625\n",
            "Current batch average train loss: 0.001611013780348003\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.953125\n",
            "Current batch average train loss: 0.0015278542414307594\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9140625\n",
            "Current batch average train loss: 0.0018750724848359823\n",
            "\n",
            "Total average train accuarcy: 0.88984\n",
            "Total average train loss: 0.0024893270939588545\n",
            "\n",
            "[ Test epoch: 40 ]\n",
            "\n",
            "Total average test accuarcy: 0.8477\n",
            "Total average test loss: 0.004647099809348583\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1950.0721323490143\n",
            "\n",
            "[ Train epoch: 41 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9375\n",
            "Current batch average train loss: 0.001906252116896212\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8828125\n",
            "Current batch average train loss: 0.0024289779830724\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.953125\n",
            "Current batch average train loss: 0.0013216183288022876\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.8984375\n",
            "Current batch average train loss: 0.0021089327055960894\n",
            "\n",
            "Total average train accuarcy: 0.89282\n",
            "Total average train loss: 0.002410491887629032\n",
            "\n",
            "[ Test epoch: 41 ]\n",
            "\n",
            "Total average test accuarcy: 0.8506\n",
            "Total average test loss: 0.004550262828171253\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 1997.7549602985382\n",
            "\n",
            "[ Train epoch: 42 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8828125\n",
            "Current batch average train loss: 0.002579379826784134\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.921875\n",
            "Current batch average train loss: 0.0017628027126193047\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.921875\n",
            "Current batch average train loss: 0.0021436158567667007\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.875\n",
            "Current batch average train loss: 0.002527713542804122\n",
            "\n",
            "Total average train accuarcy: 0.89196\n",
            "Total average train loss: 0.0024318691220879553\n",
            "\n",
            "[ Test epoch: 42 ]\n",
            "\n",
            "Total average test accuarcy: 0.8671\n",
            "Total average test loss: 0.004095764255523681\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2045.1672494411469\n",
            "\n",
            "[ Train epoch: 43 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9296875\n",
            "Current batch average train loss: 0.0016667917370796204\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.8828125\n",
            "Current batch average train loss: 0.0024233933072537184\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9296875\n",
            "Current batch average train loss: 0.0015611337730661035\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.8359375\n",
            "Current batch average train loss: 0.0029168829787522554\n",
            "\n",
            "Total average train accuarcy: 0.8942\n",
            "Total average train loss: 0.0023953794744610785\n",
            "\n",
            "[ Test epoch: 43 ]\n",
            "\n",
            "Total average test accuarcy: 0.8455\n",
            "Total average test loss: 0.004867146453261376\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2092.6395485401154\n",
            "\n",
            "[ Train epoch: 44 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9140625\n",
            "Current batch average train loss: 0.0021200438495725393\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9296875\n",
            "Current batch average train loss: 0.0015655836323276162\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.890625\n",
            "Current batch average train loss: 0.0021152724511921406\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9296875\n",
            "Current batch average train loss: 0.0019784781616181135\n",
            "\n",
            "Total average train accuarcy: 0.89428\n",
            "Total average train loss: 0.002375495337545872\n",
            "\n",
            "[ Test epoch: 44 ]\n",
            "\n",
            "Total average test accuarcy: 0.8169\n",
            "Total average test loss: 0.005810494577884674\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2139.9709525108337\n",
            "\n",
            "[ Train epoch: 45 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9296875\n",
            "Current batch average train loss: 0.0015209905104711652\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9140625\n",
            "Current batch average train loss: 0.0020052227191627026\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.84375\n",
            "Current batch average train loss: 0.003925658296793699\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.875\n",
            "Current batch average train loss: 0.0022555431351065636\n",
            "\n",
            "Total average train accuarcy: 0.89888\n",
            "Total average train loss: 0.0022881396692991255\n",
            "\n",
            "[ Test epoch: 45 ]\n",
            "\n",
            "Total average test accuarcy: 0.8419\n",
            "Total average test loss: 0.005039086075127125\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2187.365902900696\n",
            "\n",
            "[ Train epoch: 46 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.875\n",
            "Current batch average train loss: 0.0028339331038296223\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9140625\n",
            "Current batch average train loss: 0.002322025131434202\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.84375\n",
            "Current batch average train loss: 0.003660262329503894\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.859375\n",
            "Current batch average train loss: 0.0029720296151936054\n",
            "\n",
            "Total average train accuarcy: 0.8982\n",
            "Total average train loss: 0.0023096244832873343\n",
            "\n",
            "[ Test epoch: 46 ]\n",
            "\n",
            "Total average test accuarcy: 0.8361\n",
            "Total average test loss: 0.005225431299209595\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2235.0688557624817\n",
            "\n",
            "[ Train epoch: 47 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8671875\n",
            "Current batch average train loss: 0.0026592309586703777\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9140625\n",
            "Current batch average train loss: 0.002508215606212616\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.8984375\n",
            "Current batch average train loss: 0.001976859290152788\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9296875\n",
            "Current batch average train loss: 0.0016961038345471025\n",
            "\n",
            "Total average train accuarcy: 0.89804\n",
            "Total average train loss: 0.0022929378798604012\n",
            "\n",
            "[ Test epoch: 47 ]\n",
            "\n",
            "Total average test accuarcy: 0.8339\n",
            "Total average test loss: 0.005337957663834095\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2282.508685350418\n",
            "\n",
            "[ Train epoch: 48 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.875\n",
            "Current batch average train loss: 0.002218162175267935\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9453125\n",
            "Current batch average train loss: 0.0020743554923683405\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9140625\n",
            "Current batch average train loss: 0.0017261727480217814\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.890625\n",
            "Current batch average train loss: 0.001840708195231855\n",
            "\n",
            "Total average train accuarcy: 0.897\n",
            "Total average train loss: 0.002310129447877407\n",
            "\n",
            "[ Test epoch: 48 ]\n",
            "\n",
            "Total average test accuarcy: 0.8596\n",
            "Total average test loss: 0.00432748530805111\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2330.117298603058\n",
            "\n",
            "[ Train epoch: 49 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.8984375\n",
            "Current batch average train loss: 0.0023985758889466524\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9453125\n",
            "Current batch average train loss: 0.001379411551170051\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.8984375\n",
            "Current batch average train loss: 0.0021646323148161173\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.875\n",
            "Current batch average train loss: 0.0025449064560234547\n",
            "\n",
            "Total average train accuarcy: 0.89912\n",
            "Total average train loss: 0.002285364878475666\n",
            "\n",
            "[ Test epoch: 49 ]\n",
            "\n",
            "Total average test accuarcy: 0.8668\n",
            "Total average test loss: 0.004074336537718773\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2377.7853536605835\n",
            "\n",
            "[ Train epoch: 50 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9140625\n",
            "Current batch average train loss: 0.0018638067413121462\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9453125\n",
            "Current batch average train loss: 0.001371115678921342\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.96875\n",
            "Current batch average train loss: 0.0007909716223366559\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9375\n",
            "Current batch average train loss: 0.0016291103092953563\n",
            "\n",
            "Total average train accuarcy: 0.94562\n",
            "Total average train loss: 0.0012692046730220319\n",
            "\n",
            "[ Test epoch: 50 ]\n",
            "\n",
            "Total average test accuarcy: 0.9229\n",
            "Total average test loss: 0.0024240474723279475\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2425.1631996631622\n",
            "\n",
            "[ Train epoch: 51 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.96875\n",
            "Current batch average train loss: 0.0007489715935662389\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0005701407790184021\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9453125\n",
            "Current batch average train loss: 0.0008972054929472506\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.921875\n",
            "Current batch average train loss: 0.0016254163347184658\n",
            "\n",
            "Total average train accuarcy: 0.95932\n",
            "Total average train loss: 0.0009604524421691895\n",
            "\n",
            "[ Test epoch: 51 ]\n",
            "\n",
            "Total average test accuarcy: 0.9223\n",
            "Total average test loss: 0.0024223162554204464\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2472.606756925583\n",
            "\n",
            "[ Train epoch: 52 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.000635937147308141\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.96875\n",
            "Current batch average train loss: 0.0007952891173772514\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9609375\n",
            "Current batch average train loss: 0.0008493144414387643\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.96875\n",
            "Current batch average train loss: 0.0012527975486591458\n",
            "\n",
            "Total average train accuarcy: 0.9632\n",
            "Total average train loss: 0.0008520574175566435\n",
            "\n",
            "[ Test epoch: 52 ]\n",
            "\n",
            "Total average test accuarcy: 0.9245\n",
            "Total average test loss: 0.002441209187358618\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2520.4091153144836\n",
            "\n",
            "[ Train epoch: 53 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.96875\n",
            "Current batch average train loss: 0.0008927943999879062\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.953125\n",
            "Current batch average train loss: 0.0012596460292115808\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.0005796755431219935\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9453125\n",
            "Current batch average train loss: 0.00115714140702039\n",
            "\n",
            "Total average train accuarcy: 0.96578\n",
            "Total average train loss: 0.0007843892911449075\n",
            "\n",
            "[ Test epoch: 53 ]\n",
            "\n",
            "Total average test accuarcy: 0.9265\n",
            "Total average test loss: 0.0024185178846120835\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2567.6515820026398\n",
            "\n",
            "[ Train epoch: 54 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.953125\n",
            "Current batch average train loss: 0.0011871156748384237\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.0006873631500639021\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.96875\n",
            "Current batch average train loss: 0.0007988549768924713\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0004206037556286901\n",
            "\n",
            "Total average train accuarcy: 0.96788\n",
            "Total average train loss: 0.0007255921164900065\n",
            "\n",
            "[ Test epoch: 54 ]\n",
            "\n",
            "Total average test accuarcy: 0.9252\n",
            "Total average test loss: 0.002435779619961977\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2615.006617307663\n",
            "\n",
            "[ Train epoch: 55 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0003814874798990786\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.953125\n",
            "Current batch average train loss: 0.0013717488618567586\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.96875\n",
            "Current batch average train loss: 0.0007412467966787517\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9453125\n",
            "Current batch average train loss: 0.0006539021269418299\n",
            "\n",
            "Total average train accuarcy: 0.97214\n",
            "Total average train loss: 0.0006445124442130328\n",
            "\n",
            "[ Test epoch: 55 ]\n",
            "\n",
            "Total average test accuarcy: 0.9283\n",
            "Total average test loss: 0.0024646598383784293\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2662.8014545440674\n",
            "\n",
            "[ Train epoch: 56 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.953125\n",
            "Current batch average train loss: 0.0006616573082283139\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0003440528817009181\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.00014392779849004\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0005445706192404032\n",
            "\n",
            "Total average train accuarcy: 0.97234\n",
            "Total average train loss: 0.0006189555760473012\n",
            "\n",
            "[ Test epoch: 56 ]\n",
            "\n",
            "Total average test accuarcy: 0.9275\n",
            "Total average test loss: 0.002540588204562664\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2710.1927030086517\n",
            "\n",
            "[ Train epoch: 57 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9453125\n",
            "Current batch average train loss: 0.0008341698558069766\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.000432284374255687\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0004855396691709757\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9609375\n",
            "Current batch average train loss: 0.0009713739273138344\n",
            "\n",
            "Total average train accuarcy: 0.97432\n",
            "Total average train loss: 0.0005801063098013401\n",
            "\n",
            "[ Test epoch: 57 ]\n",
            "\n",
            "Total average test accuarcy: 0.9291\n",
            "Total average test loss: 0.00256094885841012\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2757.6136169433594\n",
            "\n",
            "[ Train epoch: 58 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0003476572164800018\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.96875\n",
            "Current batch average train loss: 0.0007616576622240245\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00032292367541231215\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9609375\n",
            "Current batch average train loss: 0.0006326930015347898\n",
            "\n",
            "Total average train accuarcy: 0.97762\n",
            "Total average train loss: 0.0005147338769957423\n",
            "\n",
            "[ Test epoch: 58 ]\n",
            "\n",
            "Total average test accuarcy: 0.9267\n",
            "Total average test loss: 0.0025846626192331315\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2805.256468296051\n",
            "\n",
            "[ Train epoch: 59 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.953125\n",
            "Current batch average train loss: 0.0009805242298170924\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0003156356106046587\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.0005274313734844327\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00032449333230033517\n",
            "\n",
            "Total average train accuarcy: 0.97744\n",
            "Total average train loss: 0.0004978549774736166\n",
            "\n",
            "[ Test epoch: 59 ]\n",
            "\n",
            "Total average test accuarcy: 0.9288\n",
            "Total average test loss: 0.0026195815593004225\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2852.5902812480927\n",
            "\n",
            "[ Train epoch: 60 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.0007263244478963315\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.0005086211604066193\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0003523855993989855\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00021086574997752905\n",
            "\n",
            "Total average train accuarcy: 0.97922\n",
            "Total average train loss: 0.00047356814613565805\n",
            "\n",
            "[ Test epoch: 60 ]\n",
            "\n",
            "Total average test accuarcy: 0.93\n",
            "Total average test loss: 0.0026050000250339507\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2900.004139184952\n",
            "\n",
            "[ Train epoch: 61 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.00020828320703003556\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.00017174941604025662\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00020745597430504858\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.96875\n",
            "Current batch average train loss: 0.00040682536200620234\n",
            "\n",
            "Total average train accuarcy: 0.98086\n",
            "Total average train loss: 0.00042600191108882425\n",
            "\n",
            "[ Test epoch: 61 ]\n",
            "\n",
            "Total average test accuarcy: 0.9306\n",
            "Total average test loss: 0.00274366892054677\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2947.80611038208\n",
            "\n",
            "[ Train epoch: 62 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00015599364996887743\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.00049947778461501\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00041004715603776276\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.000331365066813305\n",
            "\n",
            "Total average train accuarcy: 0.9817\n",
            "Total average train loss: 0.00041437205070629716\n",
            "\n",
            "[ Test epoch: 62 ]\n",
            "\n",
            "Total average test accuarcy: 0.9274\n",
            "Total average test loss: 0.002699152647703886\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 2995.173295021057\n",
            "\n",
            "[ Train epoch: 63 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0003024341131094843\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.0006205319659784436\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0004799830785486847\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.000539915228728205\n",
            "\n",
            "Total average train accuarcy: 0.98232\n",
            "Total average train loss: 0.0003967380700260401\n",
            "\n",
            "[ Test epoch: 63 ]\n",
            "\n",
            "Total average test accuarcy: 0.9318\n",
            "Total average test loss: 0.002751181701570749\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3042.4884061813354\n",
            "\n",
            "[ Train epoch: 64 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9609375\n",
            "Current batch average train loss: 0.001042172429151833\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.0001979307271540165\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9453125\n",
            "Current batch average train loss: 0.0009543274063616991\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.000525462965015322\n",
            "\n",
            "Total average train accuarcy: 0.98234\n",
            "Total average train loss: 0.0004002787320129573\n",
            "\n",
            "[ Test epoch: 64 ]\n",
            "\n",
            "Total average test accuarcy: 0.9288\n",
            "Total average test loss: 0.0027550966449081896\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3090.152130842209\n",
            "\n",
            "[ Train epoch: 65 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00037894395063631237\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00032754172571003437\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00026759019237942994\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00042598345316946507\n",
            "\n",
            "Total average train accuarcy: 0.9842\n",
            "Total average train loss: 0.00036984907849691806\n",
            "\n",
            "[ Test epoch: 65 ]\n",
            "\n",
            "Total average test accuarcy: 0.9278\n",
            "Total average test loss: 0.0028221942998468874\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3137.5617592334747\n",
            "\n",
            "[ Train epoch: 66 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.96875\n",
            "Current batch average train loss: 0.0005253622075542808\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00022363207244779915\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00018692461890168488\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00039621678297407925\n",
            "\n",
            "Total average train accuarcy: 0.9846\n",
            "Total average train loss: 0.00034925755828619\n",
            "\n",
            "[ Test epoch: 66 ]\n",
            "\n",
            "Total average test accuarcy: 0.9278\n",
            "Total average test loss: 0.002841740133613348\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3185.0138561725616\n",
            "\n",
            "[ Train epoch: 67 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.00013621515245176852\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.96875\n",
            "Current batch average train loss: 0.0006268874858506024\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00017631954688113183\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00019831230747513473\n",
            "\n",
            "Total average train accuarcy: 0.9856\n",
            "Total average train loss: 0.000321724301809445\n",
            "\n",
            "[ Test epoch: 67 ]\n",
            "\n",
            "Total average test accuarcy: 0.9266\n",
            "Total average test loss: 0.003024730847030878\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3232.670146226883\n",
            "\n",
            "[ Train epoch: 68 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.0001449841511202976\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00033642532071098685\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0006360611878335476\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.0001775391720002517\n",
            "\n",
            "Total average train accuarcy: 0.98562\n",
            "Total average train loss: 0.0003249872936913744\n",
            "\n",
            "[ Test epoch: 68 ]\n",
            "\n",
            "Total average test accuarcy: 0.9291\n",
            "Total average test loss: 0.002892310842871666\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3280.1572971343994\n",
            "\n",
            "[ Train epoch: 69 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00028669260791502893\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0001976841303985566\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.0004546493582893163\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0003782930434681475\n",
            "\n",
            "Total average train accuarcy: 0.98638\n",
            "Total average train loss: 0.0003086345324572176\n",
            "\n",
            "[ Test epoch: 69 ]\n",
            "\n",
            "Total average test accuarcy: 0.928\n",
            "Total average test loss: 0.003000311054289341\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3327.800882577896\n",
            "\n",
            "[ Train epoch: 70 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0002605486079119146\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00037673275801353157\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 9.448195487493649e-05\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9609375\n",
            "Current batch average train loss: 0.0003862560843117535\n",
            "\n",
            "Total average train accuarcy: 0.9864\n",
            "Total average train loss: 0.00031038393127266316\n",
            "\n",
            "[ Test epoch: 70 ]\n",
            "\n",
            "Total average test accuarcy: 0.9299\n",
            "Total average test loss: 0.002948784029483795\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3375.427313566208\n",
            "\n",
            "[ Train epoch: 71 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00022544896637555212\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00015326989523600787\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0002775917819235474\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.000106402461824473\n",
            "\n",
            "Total average train accuarcy: 0.98766\n",
            "Total average train loss: 0.00027782227008137854\n",
            "\n",
            "[ Test epoch: 71 ]\n",
            "\n",
            "Total average test accuarcy: 0.9263\n",
            "Total average test loss: 0.0030741240434348583\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3422.9658296108246\n",
            "\n",
            "[ Train epoch: 72 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.00040535355219617486\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00019312638323754072\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.0003102280606981367\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0001357517030555755\n",
            "\n",
            "Total average train accuarcy: 0.98856\n",
            "Total average train loss: 0.00027119140293449165\n",
            "\n",
            "[ Test epoch: 72 ]\n",
            "\n",
            "Total average test accuarcy: 0.9297\n",
            "Total average test loss: 0.0031012046232819558\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3470.5470683574677\n",
            "\n",
            "[ Train epoch: 73 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.00016586306446697563\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00014597793051507324\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0002014873462030664\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00016008973761927336\n",
            "\n",
            "Total average train accuarcy: 0.98848\n",
            "Total average train loss: 0.0002707860780134797\n",
            "\n",
            "[ Test epoch: 73 ]\n",
            "\n",
            "Total average test accuarcy: 0.9269\n",
            "Total average test loss: 0.0031364577025175095\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3517.9107871055603\n",
            "\n",
            "[ Train epoch: 74 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00028478915919549763\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.0006125462823547423\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00012873329978901893\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.0002111795183736831\n",
            "\n",
            "Total average train accuarcy: 0.9895\n",
            "Total average train loss: 0.0002476013342104852\n",
            "\n",
            "[ Test epoch: 74 ]\n",
            "\n",
            "Total average test accuarcy: 0.9282\n",
            "Total average test loss: 0.003102624127268791\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3565.5538091659546\n",
            "\n",
            "[ Train epoch: 75 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0001679553824942559\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.00011320420890115201\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00020958101958967745\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.00017718262097332627\n",
            "\n",
            "Total average train accuarcy: 0.98846\n",
            "Total average train loss: 0.0002543855045270175\n",
            "\n",
            "[ Test epoch: 75 ]\n",
            "\n",
            "Total average test accuarcy: 0.9264\n",
            "Total average test loss: 0.0032445852153003218\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3613.0850114822388\n",
            "\n",
            "[ Train epoch: 76 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0003067668294534087\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00019057918689213693\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.0005679294699802995\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00022516484023071826\n",
            "\n",
            "Total average train accuarcy: 0.9893\n",
            "Total average train loss: 0.0002456426671566442\n",
            "\n",
            "[ Test epoch: 76 ]\n",
            "\n",
            "Total average test accuarcy: 0.9271\n",
            "Total average test loss: 0.003118903374671936\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3660.573405981064\n",
            "\n",
            "[ Train epoch: 77 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.00041356091969646513\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0002937795070465654\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0002937252284027636\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.00014290164108388126\n",
            "\n",
            "Total average train accuarcy: 0.98956\n",
            "Total average train loss: 0.0002466084355348721\n",
            "\n",
            "[ Test epoch: 77 ]\n",
            "\n",
            "Total average test accuarcy: 0.9281\n",
            "Total average test loss: 0.0031984796941280365\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3707.8991072177887\n",
            "\n",
            "[ Train epoch: 78 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00026245941990055144\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00028281411505304277\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00015238058404065669\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0001574923808220774\n",
            "\n",
            "Total average train accuarcy: 0.99048\n",
            "Total average train loss: 0.00022600409952923655\n",
            "\n",
            "[ Test epoch: 78 ]\n",
            "\n",
            "Total average test accuarcy: 0.9293\n",
            "Total average test loss: 0.0030910829454660416\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3755.669047832489\n",
            "\n",
            "[ Train epoch: 79 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.00015671554137952626\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.00013581191888079047\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0004194233624730259\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00032226808252744377\n",
            "\n",
            "Total average train accuarcy: 0.99022\n",
            "Total average train loss: 0.00023411529619712384\n",
            "\n",
            "[ Test epoch: 79 ]\n",
            "\n",
            "Total average test accuarcy: 0.9272\n",
            "Total average test loss: 0.0032073638640344143\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3803.0398213863373\n",
            "\n",
            "[ Train epoch: 80 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 6.604191003134474e-05\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.00037597178015857935\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0002585981856100261\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00017846807895693928\n",
            "\n",
            "Total average train accuarcy: 0.98938\n",
            "Total average train loss: 0.00023456489003030584\n",
            "\n",
            "[ Test epoch: 80 ]\n",
            "\n",
            "Total average test accuarcy: 0.9287\n",
            "Total average test loss: 0.0032218813732266425\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3850.511315345764\n",
            "\n",
            "[ Train epoch: 81 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00015851717034820467\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0001441298081772402\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.00036865705624222755\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00015052611706778407\n",
            "\n",
            "Total average train accuarcy: 0.98912\n",
            "Total average train loss: 0.0002506883289758116\n",
            "\n",
            "[ Test epoch: 81 ]\n",
            "\n",
            "Total average test accuarcy: 0.9256\n",
            "Total average test loss: 0.003486790852248669\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3898.367232322693\n",
            "\n",
            "[ Train epoch: 82 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.00010502152144908905\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00010183882113778964\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.0005015654605813324\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 5.607748607872054e-05\n",
            "\n",
            "Total average train accuarcy: 0.9898\n",
            "Total average train loss: 0.0002312562288949266\n",
            "\n",
            "[ Test epoch: 82 ]\n",
            "\n",
            "Total average test accuarcy: 0.9229\n",
            "Total average test loss: 0.0034562408730387686\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3945.886942386627\n",
            "\n",
            "[ Train epoch: 83 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00023480386880692095\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 3.380288399057463e-05\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00022497605823446065\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 6.976458098506555e-05\n",
            "\n",
            "Total average train accuarcy: 0.98932\n",
            "Total average train loss: 0.0002390576853742823\n",
            "\n",
            "[ Test epoch: 83 ]\n",
            "\n",
            "Total average test accuarcy: 0.93\n",
            "Total average test loss: 0.003195941010862589\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 3993.2091760635376\n",
            "\n",
            "[ Train epoch: 84 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.00025547147379256785\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00015640967467334121\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0002513007784727961\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0001740346197038889\n",
            "\n",
            "Total average train accuarcy: 0.9912\n",
            "Total average train loss: 0.00020414137089625001\n",
            "\n",
            "[ Test epoch: 84 ]\n",
            "\n",
            "Total average test accuarcy: 0.9264\n",
            "Total average test loss: 0.0032638713270425794\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4040.984466314316\n",
            "\n",
            "[ Train epoch: 85 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00016401876928284764\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.00012083137698937207\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00027096905978396535\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0002631743554957211\n",
            "\n",
            "Total average train accuarcy: 0.99004\n",
            "Total average train loss: 0.00023158234922215343\n",
            "\n",
            "[ Test epoch: 85 ]\n",
            "\n",
            "Total average test accuarcy: 0.9286\n",
            "Total average test loss: 0.003214302644878626\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4088.479821205139\n",
            "\n",
            "[ Train epoch: 86 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00015315385826397687\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.0003788819594774395\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0002056827797787264\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0001279237330891192\n",
            "\n",
            "Total average train accuarcy: 0.99098\n",
            "Total average train loss: 0.00021509818327147514\n",
            "\n",
            "[ Test epoch: 86 ]\n",
            "\n",
            "Total average test accuarcy: 0.925\n",
            "Total average test loss: 0.003319557834789157\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4135.917604207993\n",
            "\n",
            "[ Train epoch: 87 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.00041190587216988206\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0002186263882322237\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00013870901602786034\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00039618738810531795\n",
            "\n",
            "Total average train accuarcy: 0.99098\n",
            "Total average train loss: 0.00020823436866514384\n",
            "\n",
            "[ Test epoch: 87 ]\n",
            "\n",
            "Total average test accuarcy: 0.9241\n",
            "Total average test loss: 0.0034801291666924955\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4183.637172698975\n",
            "\n",
            "[ Train epoch: 88 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0002926054294221103\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00019505011732690036\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00023614132078364491\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.000345060252584517\n",
            "\n",
            "Total average train accuarcy: 0.99058\n",
            "Total average train loss: 0.0002219126201979816\n",
            "\n",
            "[ Test epoch: 88 ]\n",
            "\n",
            "Total average test accuarcy: 0.9252\n",
            "Total average test loss: 0.0032051026895642282\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4231.141899108887\n",
            "\n",
            "[ Train epoch: 89 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 4.4947824790142477e-05\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0001071328588295728\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00015971418179105967\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.000198036155779846\n",
            "\n",
            "Total average train accuarcy: 0.99032\n",
            "Total average train loss: 0.00021668442672118543\n",
            "\n",
            "[ Test epoch: 89 ]\n",
            "\n",
            "Total average test accuarcy: 0.9285\n",
            "Total average test loss: 0.0032470992788672447\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4278.539506196976\n",
            "\n",
            "[ Train epoch: 90 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 6.740196113241836e-05\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00022534139861818403\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.0006124587380327284\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 9.803813009057194e-05\n",
            "\n",
            "Total average train accuarcy: 0.99002\n",
            "Total average train loss: 0.00022475864236708732\n",
            "\n",
            "[ Test epoch: 90 ]\n",
            "\n",
            "Total average test accuarcy: 0.9237\n",
            "Total average test loss: 0.00345942822471261\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4326.26966881752\n",
            "\n",
            "[ Train epoch: 91 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00017715769354254007\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00031192973256111145\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.00031013102852739394\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 8.89866059878841e-05\n",
            "\n",
            "Total average train accuarcy: 0.99032\n",
            "Total average train loss: 0.00022565361610846595\n",
            "\n",
            "[ Test epoch: 91 ]\n",
            "\n",
            "Total average test accuarcy: 0.9257\n",
            "Total average test loss: 0.0034382848180830477\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4373.819670915604\n",
            "\n",
            "[ Train epoch: 92 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 4.762882235809229e-05\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 4.550911398837343e-05\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.0003667012497317046\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00025937778991647065\n",
            "\n",
            "Total average train accuarcy: 0.99124\n",
            "Total average train loss: 0.0002038813615543768\n",
            "\n",
            "[ Test epoch: 92 ]\n",
            "\n",
            "Total average test accuarcy: 0.922\n",
            "Total average test loss: 0.003561084208637476\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4421.364988327026\n",
            "\n",
            "[ Train epoch: 93 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.00044312281534075737\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 6.600092456210405e-05\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0004930046270601451\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0002295095328008756\n",
            "\n",
            "Total average train accuarcy: 0.99208\n",
            "Total average train loss: 0.00018581530421506612\n",
            "\n",
            "[ Test epoch: 93 ]\n",
            "\n",
            "Total average test accuarcy: 0.9232\n",
            "Total average test loss: 0.0035222395054996013\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4469.001174211502\n",
            "\n",
            "[ Train epoch: 94 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 4.148104562773369e-05\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.00014502386329695582\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0003013964742422104\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00039165158523246646\n",
            "\n",
            "Total average train accuarcy: 0.98978\n",
            "Total average train loss: 0.0002346575625287369\n",
            "\n",
            "[ Test epoch: 94 ]\n",
            "\n",
            "Total average test accuarcy: 0.9242\n",
            "Total average test loss: 0.0033799244530498982\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4516.467475891113\n",
            "\n",
            "[ Train epoch: 95 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0002635123673826456\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00011760689812945202\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.00010164167906623334\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00022146930859889835\n",
            "\n",
            "Total average train accuarcy: 0.99022\n",
            "Total average train loss: 0.00022571675026323646\n",
            "\n",
            "[ Test epoch: 95 ]\n",
            "\n",
            "Total average test accuarcy: 0.9253\n",
            "Total average test loss: 0.003383608014881611\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4563.787327528\n",
            "\n",
            "[ Train epoch: 96 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 0.00011830356379505247\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00018183974316343665\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00019736555987037718\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 9.686904377304018e-05\n",
            "\n",
            "Total average train accuarcy: 0.99042\n",
            "Total average train loss: 0.00021452345423866062\n",
            "\n",
            "[ Test epoch: 96 ]\n",
            "\n",
            "Total average test accuarcy: 0.9259\n",
            "Total average test loss: 0.0034584032766520976\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4611.15075135231\n",
            "\n",
            "[ Train epoch: 97 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.0006477186689153314\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00014599163841921836\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.00031119267805479467\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0001307393395109102\n",
            "\n",
            "Total average train accuarcy: 0.9901\n",
            "Total average train loss: 0.000228172592879273\n",
            "\n",
            "[ Test epoch: 97 ]\n",
            "\n",
            "Total average test accuarcy: 0.9247\n",
            "Total average test loss: 0.0033613973528146745\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4658.519613981247\n",
            "\n",
            "[ Train epoch: 98 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00013550565927289426\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 7.822114275768399e-05\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0002526076859794557\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00030851768678985536\n",
            "\n",
            "Total average train accuarcy: 0.9918\n",
            "Total average train loss: 0.00019310223948210478\n",
            "\n",
            "[ Test epoch: 98 ]\n",
            "\n",
            "Total average test accuarcy: 0.9209\n",
            "Total average test loss: 0.0037249319069087507\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4706.129812002182\n",
            "\n",
            "[ Train epoch: 99 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.00023414843599312007\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.000135899186716415\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 1.1553000149433501e-05\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00017808536358643323\n",
            "\n",
            "Total average train accuarcy: 0.99172\n",
            "Total average train loss: 0.00019601494420319797\n",
            "\n",
            "[ Test epoch: 99 ]\n",
            "\n",
            "Total average test accuarcy: 0.918\n",
            "Total average test loss: 0.003832404049485922\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4753.435591220856\n",
            "\n",
            "[ Train epoch: 100 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00018277655181009322\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 5.735940794693306e-05\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 4.166558574070223e-05\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 2.8385871701175347e-05\n",
            "\n",
            "Total average train accuarcy: 0.99422\n",
            "Total average train loss: 0.000140932076505851\n",
            "\n",
            "[ Test epoch: 100 ]\n",
            "\n",
            "Total average test accuarcy: 0.9303\n",
            "Total average test loss: 0.0030805069249123336\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4800.886350393295\n",
            "\n",
            "[ Train epoch: 101 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.00020365456293802708\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.000176574380020611\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 2.6271916794939898e-05\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 4.21385484514758e-05\n",
            "\n",
            "Total average train accuarcy: 0.99634\n",
            "Total average train loss: 0.00010065033537917771\n",
            "\n",
            "[ Test epoch: 101 ]\n",
            "\n",
            "Total average test accuarcy: 0.9307\n",
            "Total average test loss: 0.003109698049724102\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4848.675964593887\n",
            "\n",
            "[ Train epoch: 102 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 2.9025626645307057e-05\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 3.2038817153079435e-05\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 3.628618651418947e-05\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 2.365653017477598e-05\n",
            "\n",
            "Total average train accuarcy: 0.99698\n",
            "Total average train loss: 8.798921161098405e-05\n",
            "\n",
            "[ Test epoch: 102 ]\n",
            "\n",
            "Total average test accuarcy: 0.9306\n",
            "Total average test loss: 0.003094070395082235\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4895.977475643158\n",
            "\n",
            "[ Train epoch: 103 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 7.277927943505347e-05\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 0.984375\n",
            "Current batch average train loss: 0.0003168020339217037\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9765625\n",
            "Current batch average train loss: 0.00044203645666129887\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 2.263031456095632e-05\n",
            "\n",
            "Total average train accuarcy: 0.99768\n",
            "Total average train loss: 7.180764843476937e-05\n",
            "\n",
            "[ Test epoch: 103 ]\n",
            "\n",
            "Total average test accuarcy: 0.9314\n",
            "Total average test loss: 0.003105146495252848\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4943.361288547516\n",
            "\n",
            "[ Train epoch: 104 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 3.852938971249387e-05\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 7.147441010602051e-06\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 0.0001269586937269196\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 0.9921875\n",
            "Current batch average train loss: 7.268320041475818e-05\n",
            "\n",
            "Total average train accuarcy: 0.99782\n",
            "Total average train loss: 6.980819609365426e-05\n",
            "\n",
            "[ Test epoch: 104 ]\n",
            "\n",
            "Total average test accuarcy: 0.9327\n",
            "Total average test loss: 0.0030892209649086\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 4991.145696640015\n",
            "\n",
            "[ Train epoch: 105 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 1.650628837523982e-05\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 9.24080959521234e-05\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 4.4517742935568094e-05\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 3.499844024190679e-05\n",
            "\n",
            "Total average train accuarcy: 0.99824\n",
            "Total average train loss: 6.438193121924996e-05\n",
            "\n",
            "[ Test epoch: 105 ]\n",
            "\n",
            "Total average test accuarcy: 0.9327\n",
            "Total average test loss: 0.0031101378928869963\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 5038.413337469101\n",
            "\n",
            "[ Train epoch: 106 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 6.34149182587862e-05\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 6.272798782447353e-05\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 4.035064921481535e-05\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 1.89311322174035e-05\n",
            "\n",
            "Total average train accuarcy: 0.99804\n",
            "Total average train loss: 6.254336051817518e-05\n",
            "\n",
            "[ Test epoch: 106 ]\n",
            "\n",
            "Total average test accuarcy: 0.9325\n",
            "Total average test loss: 0.003104349473118782\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 5085.750273704529\n",
            "\n",
            "[ Train epoch: 107 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 2.5716022719279863e-05\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 1.882891774585005e-05\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 1.9306031390442513e-05\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 2.285182745254133e-05\n",
            "\n",
            "Total average train accuarcy: 0.9985\n",
            "Total average train loss: 5.595967518049292e-05\n",
            "\n",
            "[ Test epoch: 107 ]\n",
            "\n",
            "Total average test accuarcy: 0.9323\n",
            "Total average test loss: 0.0030986266952008007\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 5133.4882662296295\n",
            "\n",
            "[ Train epoch: 108 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 1.812821392377373e-05\n",
            "\n",
            "Current batch: 100\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 3.124327849945985e-05\n",
            "\n",
            "Current batch: 200\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 3.4397817216813564e-05\n",
            "\n",
            "Current batch: 300\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 5.870446329936385e-05\n",
            "\n",
            "Total average train accuarcy: 0.99836\n",
            "Total average train loss: 5.538101411191746e-05\n",
            "\n",
            "[ Test epoch: 108 ]\n",
            "\n",
            "Total average test accuarcy: 0.9342\n",
            "Total average test loss: 0.0030957074314355852\n",
            "Model Saved!\n",
            "\n",
            "Time elapsed: 5180.7592186927795\n",
            "\n",
            "[ Train epoch: 109 ]\n",
            "\n",
            "Current batch: 0\n",
            "Current batch average train accuracy: 1.0\n",
            "Current batch average train loss: 6.884651520522311e-05\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    lr = learning_rate\n",
        "    if epoch >= 50:\n",
        "        lr /= 10\n",
        "    if epoch >= 100:\n",
        "        lr /= 10\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(0, 10):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    print('\\nTime elapsed:', time.time() - start_time)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7FMvuTnEWR1t",
        "rpwnOddtWXDN"
      ],
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPbY4pllhJcUclo1OzfPixs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}